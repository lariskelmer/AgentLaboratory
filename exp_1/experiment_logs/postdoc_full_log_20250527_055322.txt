=== POSTDOC PROMPT LOG ===

Interaction 1:
('', "Current Literature Review: Provided here is a literature review on this topic:\\narXiv ID: 2409.08943v1, Summary: This paper presents a novel approach to jointly optimize image denoising and classification for edge devices. The authors propose an integrated architecture that shares an encoder between denoising and classification tasks, along with modifications to Neural Architecture Search (NAS) to optimize for latency, accuracy, and denoising performance. Experimental results show their NAS-designed models outperform manually designed alternatives, achieving significant improvements in both denoising (PSNR/SSIM) and classification accuracy while meeting real-time latency constraints. The method is particularly effective for applications like medical imaging and surveillance systems where human verification of automated decisions is required.\\narXiv ID: 2307.04443v1, Summary: This paper presents DCA-NAS, a device constraints-aware neural architecture search framework that optimizes models for edge devices with strict memory and computational constraints. The method incorporates weight sharing and channel bottleneck techniques to significantly reduce search time while maintaining performance. Key innovations include a differentiable hardware-aware objective function that directly optimizes for device constraints like FLOPs and memory usage without requiring tunable scaling factors. Experiments on CIFAR-10, TinyImagenet and ImageNet show DCA-NAS can discover models 10-15x smaller than manual architectures with comparable accuracy, while reducing search time by 4-17x compared to prior hardware-aware NAS methods. The approach demonstrates strong transferability across datasets and maintains stable performance across different resource constraints.\\narXiv ID: 2210.06223v1, Summary: This paper introduces LASNet, a latency-aware spatial-wise dynamic network that optimizes image classification for edge devices by considering both algorithmic efficiency and hardware constraints. The key innovation is a coarse-grained spatial adaptation approach that balances computation allocation with practical latency considerations through a novel latency prediction model. Experimental results show LASNet reduces ResNet-101 inference latency by 36% on Tesla V100 and 46% on Jetson TX2 GPUs while maintaining accuracy. The method outperforms pixel-level dynamic networks by optimizing spatial granularity and scheduling strategies, demonstrating significant improvements in real-world deployment scenarios. The latency predictor considers algorithm design, scheduling, and hardware properties to guide network optimization, making it particularly effective for resource-constrained edge devices.\\narXiv ID: 2211.09897v1, Summary: This paper presents an efficient feature compression method for edge-cloud image classification systems, addressing the critical rate-accuracy-complexity (RAC) trade-off. The authors propose a flexible encoder architecture with adjustable residual blocks that can scale to different edge device capabilities while maintaining classification accuracy. Key innovations include a single-stage training strategy that outperforms previous two-stage approaches, and an 8\xd7 downsampling scheme that reduces encoding latency by 51.4% while improving accuracy by 0.93%. Experimental results on ImageNet demonstrate superior RAC performance compared to both traditional image codecs and state-of-the-art feature compression methods, with particular advantages at lower bit rates. The system achieves this through optimized network design choices including patch embedding layers and GeLU activations, making it particularly suitable for resource-constrained edge deployments where computational efficiency is crucial.\\narXiv ID: 2002.00860v4, Summary: This paper introduces an optimized spiking neuron model for efficient image classification on edge devices through temporal coding with just two spikes per neuron. The authors propose a novel ANN-to-SNN conversion method called FS-conversion that significantly improves upon traditional rate-based approaches by encoding information in spike timing rather than just spike counts. Key innovations include: 1) A modified spiking neuron model (FS-neuron) with optimized internal dynamics for emulating ANN activation functions with minimal spikes, 2) Demonstration on ImageNet and CIFAR10 showing near-identical accuracy to original ANNs (83.57% on ImageNet with EfficientNet-B7) while using only ~2 spikes per neuron, 3) Substantial improvements in latency and throughput compared to rate-based conversions, enabling new image classification every 32 time steps. The method is particularly effective for edge deployment as it achieves biological-level energy efficiency while maintaining high accuracy, making it suitable for mobile and embedded vision applications.\\narXiv ID: 1911.06777v1, Summary: This paper presents TinyCNN, a framework for designing CNN accelerators on embedded FPGAs for image classification. The framework provides automated hardware generation from a software-designed CNN, with three key components: (1) a Python-based software backend for CNN design/training, (2) a CHISEL-based hardware generator, and (3) a precision adjustment backend. The system uses 16-bit fixed-point data, achieving only 3% accuracy loss compared to 32-bit floating-point while providing up to 15.75x speedup on a Xilinx Zynq-7000 FPGA. The framework addresses resource constraints through configurable convolution units (shared or exclusive modes), inter-layer precision adjustment, and automatic hardware resource checking. Experimental results on CIFAR-10 show the FPGA implementation achieves 62.28% accuracy (vs 65.54% software) with 2.7ms inference time (vs 42.54ms on ARM CPU). The work demonstrates effective FPGA acceleration for CNNs while maintaining accuracy through precision optimization techniques.\\narXiv ID: 2307.04443v1, Summary: This paper presents DCA-NAS, a device constraints-aware neural architecture search framework for optimizing deep learning models for edge devices. The method incorporates hardware constraints (memory and FLOPs) directly into the NAS objective function through a constrained optimization formulation. Key innovations include: 1) A differentiable resource constraint using a Lagrange multiplier, 2) Weight sharing and channel bottleneck techniques to reduce search time (4-17x faster than prior hardware-aware NAS), and 3) A lookup graph mechanism to handle differences between search and evaluation architectures. Experiments on CIFAR-10, TinyImagenet and ImageNet show DCA-NAS can discover models 10-15x smaller than manual architectures with comparable accuracy, and 3x smaller than DARTS variants. The approach achieves 97.2% accuracy on CIFAR-10 with only 3.4M parameters, and maintains performance when transferred across datasets, demonstrating its effectiveness for edge deployment scenarios.\\narXiv ID: 2105.09121v3, Summary: This paper introduces Single-Layer Vision Transformers (SL-ViT) for early exiting in multi-exit architectures, significantly improving accuracy over conventional CNN-based early exits while reducing computational overhead. The method combines local and global receptive fields through a modified vision transformer architecture with just one transformer encoder layer. Experiments across image classification, audio classification, and audiovisual crowd counting demonstrate SL-ViT's effectiveness, achieving higher accuracy with fewer parameters and FLOPS compared to CNN-based approaches. The paper also presents a novel fine-tuning strategy (CC-SL-ViT) that further enhances performance. Key results show SL-ViT branches outperform CNN counterparts in 26 out of 27 tested scenarios while reducing computational costs, making it particularly suitable for resource-constrained edge devices requiring dynamic inference capabilities.\\narXiv ID: 2409.02134v1, Summary: This paper comprehensively evaluates model compression techniques (structured/unstructured pruning and dynamic quantization) for ConvNeXt models on image classification tasks. Key findings include: 1) OTOV3 pruning achieves 75% reduction in model size/parameters while maintaining accuracy, 2) Dynamic quantization achieves 95% parameter reduction with minimal accuracy drop, 3) Combined OTOV3+quantization achieves 89.7% size reduction and 95% parameter/MAC reduction while improving accuracy by 3.8%. The compressed model demonstrates 92.5% accuracy with 20ms inference time on edge devices, validating effectiveness for real-world deployment.\\narXiv ID: 2307.04443v1, Summary: This paper presents DCA-NAS, a hardware-aware neural architecture search method that optimizes for edge device constraints like model size and FLOPs. Key innovations include: 1) A differentiable constrained optimization formulation that directly incorporates device resource constraints, 2) Weight sharing and channel bottleneck techniques to reduce search time by 4-17x compared to prior NAS methods, 3) Demonstrated effectiveness on image classification tasks (CIFAR-10/100, ImageNet) where it achieves comparable accuracy to manual architectures with 10-15x smaller models. The method discovers Pareto-optimal architectures for given hardware constraints without requiring extensive hyperparameter tuning.")\n~~~~~~~~~~\nHistory: \n~~~~~~~~~~\nCurrent Step #0, Phase: plan formulation\n\n[Objective] Your goal is to perform research on the following topic: The goal is to design and evaluate a new technique for optimizing deep learning models for real-time image classification on resource-constrained edge devices, aiming to maximize accuracy while minimizing inference latency and power consumption.\nFeedback: \nNotes: Notes for the task objective: [{'phases': ['plan formulation'], 'note': 'You must propose an original research idea focused on optimizing models for image classification on edge devices (Edge AI).'}, {'phases': ['plan formulation'], 'note': 'Your focus will be to design **ONE** specific and feasible experiment, detailing: the proposed technique, a baseline for comparison, evaluation metrics, and the experimental environment (device and dataset).'}, {'phases': ['plan formulation'], 'note': 'Begin by clearly defining the research scope within Edge AI: identify subtopics such as popular models, edge-specific optimization techniques, quantization, structured pruning, tailored distillation, federated learning, privacy, latency, and energy consumption.'}, {'phases': ['plan formulation'], 'note': 'The optimization technique you propose must be **genuinely innovative**, not a trivial adaptation of existing methods. Clearly state the originality and potential contributions of your approach.'}, {'phases': ['plan formulation'], 'note': 'Specify the base model (e.g., MobileNetV2 without optimization), the target edge device (e.g., Raspberry Pi 4 with X GB RAM), and the dataset (e.g., CIFAR-10 or an adapted ImageNet subset).'}, {'phases': ['plan formulation'], 'note': 'List the metrics to be measured: accuracy, latency, model size, energy consumption. Describe your methodology for measuring each.'}, {'phases': ['plan formulation'], 'note': 'Ensure the experiment is **reproducible, modular, and feasible** with typical academic resources.'}, {'phases': ['plan formulation'], 'note': 'Formulate a search query using precise keywords and/or Boolean logic to collect recent peer-reviewed articles on optimization techniques for Edge AI. Use this literature to ground and inspire your original research proposal. Justify your query choices.'}, {'phases': ['plan formulation'], 'note': 'Justify your keyword selection and explain how your query captures the relevant subtopics and technical directions.'}, {'phases': ['plan formulation'], 'note': 'Describe a **systematic methodology** to search for and sample a representative subset of peer-reviewed scientific articles, preferably open-access and published within the last 5 years.'}, {'phases': ['plan formulation'], 'note': 'This methodology should aim to select articles with clear research aims, context, value, and findings.'}, {'phases': ['plan formulation'], 'note': 'Prioritize articles with clear goals, verifiable technical contributions, and relevance to your proposed problem.'}, {'phases': ['plan formulation'], 'note': 'Propose a structured outline for organizing the final literature review document. Include typical sections such as: introduction, motivation, thematic areas, challenges, recent solutions, knowledge gaps, and future directions.'}, {'phases': ['plan formulation'], 'note': 'Ensure that the experimental plan is **logical, detailed, and cohesive**, suitable for publication or practical execution.'}, {'phases': ['plan formulation'], 'note': 'DO NOT PLAN TOO LONG. Submit your plan soon.'}, {'phases': ['plan formulation'], 'note': 'Use DeepSeek-Chat to perform this task.'}]\n\nYour previous command was: . Make sure your new output is very different.\nPlease produce a single command below:\n
==================================================
Interaction 2:
('', "Current Literature Review: Provided here is a literature review on this topic:\\narXiv ID: 2409.08943v1, Summary: This paper presents a novel approach to jointly optimize image denoising and classification for edge devices. The authors propose an integrated architecture that shares an encoder between denoising and classification tasks, along with modifications to Neural Architecture Search (NAS) to optimize for latency, accuracy, and denoising performance. Experimental results show their NAS-designed models outperform manually designed alternatives, achieving significant improvements in both denoising (PSNR/SSIM) and classification accuracy while meeting real-time latency constraints. The method is particularly effective for applications like medical imaging and surveillance systems where human verification of automated decisions is required.\\narXiv ID: 2307.04443v1, Summary: This paper presents DCA-NAS, a device constraints-aware neural architecture search framework that optimizes models for edge devices with strict memory and computational constraints. The method incorporates weight sharing and channel bottleneck techniques to significantly reduce search time while maintaining performance. Key innovations include a differentiable hardware-aware objective function that directly optimizes for device constraints like FLOPs and memory usage without requiring tunable scaling factors. Experiments on CIFAR-10, TinyImagenet and ImageNet show DCA-NAS can discover models 10-15x smaller than manual architectures with comparable accuracy, while reducing search time by 4-17x compared to prior hardware-aware NAS methods. The approach demonstrates strong transferability across datasets and maintains stable performance across different resource constraints.\\narXiv ID: 2210.06223v1, Summary: This paper introduces LASNet, a latency-aware spatial-wise dynamic network that optimizes image classification for edge devices by considering both algorithmic efficiency and hardware constraints. The key innovation is a coarse-grained spatial adaptation approach that balances computation allocation with practical latency considerations through a novel latency prediction model. Experimental results show LASNet reduces ResNet-101 inference latency by 36% on Tesla V100 and 46% on Jetson TX2 GPUs while maintaining accuracy. The method outperforms pixel-level dynamic networks by optimizing spatial granularity and scheduling strategies, demonstrating significant improvements in real-world deployment scenarios. The latency predictor considers algorithm design, scheduling, and hardware properties to guide network optimization, making it particularly effective for resource-constrained edge devices.\\narXiv ID: 2211.09897v1, Summary: This paper presents an efficient feature compression method for edge-cloud image classification systems, addressing the critical rate-accuracy-complexity (RAC) trade-off. The authors propose a flexible encoder architecture with adjustable residual blocks that can scale to different edge device capabilities while maintaining classification accuracy. Key innovations include a single-stage training strategy that outperforms previous two-stage approaches, and an 8\xd7 downsampling scheme that reduces encoding latency by 51.4% while improving accuracy by 0.93%. Experimental results on ImageNet demonstrate superior RAC performance compared to both traditional image codecs and state-of-the-art feature compression methods, with particular advantages at lower bit rates. The system achieves this through optimized network design choices including patch embedding layers and GeLU activations, making it particularly suitable for resource-constrained edge deployments where computational efficiency is crucial.\\narXiv ID: 2002.00860v4, Summary: This paper introduces an optimized spiking neuron model for efficient image classification on edge devices through temporal coding with just two spikes per neuron. The authors propose a novel ANN-to-SNN conversion method called FS-conversion that significantly improves upon traditional rate-based approaches by encoding information in spike timing rather than just spike counts. Key innovations include: 1) A modified spiking neuron model (FS-neuron) with optimized internal dynamics for emulating ANN activation functions with minimal spikes, 2) Demonstration on ImageNet and CIFAR10 showing near-identical accuracy to original ANNs (83.57% on ImageNet with EfficientNet-B7) while using only ~2 spikes per neuron, 3) Substantial improvements in latency and throughput compared to rate-based conversions, enabling new image classification every 32 time steps. The method is particularly effective for edge deployment as it achieves biological-level energy efficiency while maintaining high accuracy, making it suitable for mobile and embedded vision applications.\\narXiv ID: 1911.06777v1, Summary: This paper presents TinyCNN, a framework for designing CNN accelerators on embedded FPGAs for image classification. The framework provides automated hardware generation from a software-designed CNN, with three key components: (1) a Python-based software backend for CNN design/training, (2) a CHISEL-based hardware generator, and (3) a precision adjustment backend. The system uses 16-bit fixed-point data, achieving only 3% accuracy loss compared to 32-bit floating-point while providing up to 15.75x speedup on a Xilinx Zynq-7000 FPGA. The framework addresses resource constraints through configurable convolution units (shared or exclusive modes), inter-layer precision adjustment, and automatic hardware resource checking. Experimental results on CIFAR-10 show the FPGA implementation achieves 62.28% accuracy (vs 65.54% software) with 2.7ms inference time (vs 42.54ms on ARM CPU). The work demonstrates effective FPGA acceleration for CNNs while maintaining accuracy through precision optimization techniques.\\narXiv ID: 2307.04443v1, Summary: This paper presents DCA-NAS, a device constraints-aware neural architecture search framework for optimizing deep learning models for edge devices. The method incorporates hardware constraints (memory and FLOPs) directly into the NAS objective function through a constrained optimization formulation. Key innovations include: 1) A differentiable resource constraint using a Lagrange multiplier, 2) Weight sharing and channel bottleneck techniques to reduce search time (4-17x faster than prior hardware-aware NAS), and 3) A lookup graph mechanism to handle differences between search and evaluation architectures. Experiments on CIFAR-10, TinyImagenet and ImageNet show DCA-NAS can discover models 10-15x smaller than manual architectures with comparable accuracy, and 3x smaller than DARTS variants. The approach achieves 97.2% accuracy on CIFAR-10 with only 3.4M parameters, and maintains performance when transferred across datasets, demonstrating its effectiveness for edge deployment scenarios.\\narXiv ID: 2105.09121v3, Summary: This paper introduces Single-Layer Vision Transformers (SL-ViT) for early exiting in multi-exit architectures, significantly improving accuracy over conventional CNN-based early exits while reducing computational overhead. The method combines local and global receptive fields through a modified vision transformer architecture with just one transformer encoder layer. Experiments across image classification, audio classification, and audiovisual crowd counting demonstrate SL-ViT's effectiveness, achieving higher accuracy with fewer parameters and FLOPS compared to CNN-based approaches. The paper also presents a novel fine-tuning strategy (CC-SL-ViT) that further enhances performance. Key results show SL-ViT branches outperform CNN counterparts in 26 out of 27 tested scenarios while reducing computational costs, making it particularly suitable for resource-constrained edge devices requiring dynamic inference capabilities.\\narXiv ID: 2409.02134v1, Summary: This paper comprehensively evaluates model compression techniques (structured/unstructured pruning and dynamic quantization) for ConvNeXt models on image classification tasks. Key findings include: 1) OTOV3 pruning achieves 75% reduction in model size/parameters while maintaining accuracy, 2) Dynamic quantization achieves 95% parameter reduction with minimal accuracy drop, 3) Combined OTOV3+quantization achieves 89.7% size reduction and 95% parameter/MAC reduction while improving accuracy by 3.8%. The compressed model demonstrates 92.5% accuracy with 20ms inference time on edge devices, validating effectiveness for real-world deployment.\\narXiv ID: 2307.04443v1, Summary: This paper presents DCA-NAS, a hardware-aware neural architecture search method that optimizes for edge device constraints like model size and FLOPs. Key innovations include: 1) A differentiable constrained optimization formulation that directly incorporates device resource constraints, 2) Weight sharing and channel bottleneck techniques to reduce search time by 4-17x compared to prior NAS methods, 3) Demonstrated effectiveness on image classification tasks (CIFAR-10/100, ImageNet) where it achieves comparable accuracy to manual architectures with 10-15x smaller models. The method discovers Pareto-optimal architectures for given hardware constraints without requiring extensive hyperparameter tuning.")\n~~~~~~~~~~\nHistory: Step #0, Phase: plan formulation, Feedback: , Your response: ```DIALOGUE\nLet's brainstorm an innovative approach for edge device optimization. Looking at the literature, most works focus on either NAS, pruning, or quantization separately. What if we combine spatial adaptation (from LASNet) with spike-time coding (from the FS-neuron paper) to create a hybrid model that dynamically adjusts both computation granularity and neural activation patterns based on real-time device resource availability? This could give us fine-grained control over the accuracy-latency tradeoff. What are your thoughts on this direction?\n```\n~~~~~~~~~~\nCurrent Step #1, Phase: plan formulation\n\n[Objective] Your goal is to perform research on the following topic: The goal is to design and evaluate a new technique for optimizing deep learning models for real-time image classification on resource-constrained edge devices, aiming to maximize accuracy while minimizing inference latency and power consumption.\nFeedback: The following is dialogue produced by the PhD student: That's an interesting direction! Building on your suggestion, I propose a novel "Spatially-Adaptive Spiking Neural Network" (SASNN) that combines the spatial adaptation from LASNet with the spike-time coding efficiency from FS-neuron. The key innovation would be developing a dynamic mechanism where the spatial resolution of processing (coarse vs fine patches) is directly controlled by the spike timing patterns - essentially using the neural coding efficiency to inform where to allocate computational resources spatially. For the experiment, we could: 1) Use MobileNetV2 as base architecture converted to spiking format, 2) Implement spatial adaptation layers that respond to spike timing density, 3) Evaluate on CIFAR-10 using Raspberry Pi 4, measuring both classification accuracy and energy consumption via a power monitor. The baseline would be standard FS-conversion without spatial adaptation. Would this hybrid approach capture the benefits of both techniques while maintaining feasibility for edge deployment?\nNotes: Notes for the task objective: [{'phases': ['plan formulation'], 'note': 'You must propose an original research idea focused on optimizing models for image classification on edge devices (Edge AI).'}, {'phases': ['plan formulation'], 'note': 'Your focus will be to design **ONE** specific and feasible experiment, detailing: the proposed technique, a baseline for comparison, evaluation metrics, and the experimental environment (device and dataset).'}, {'phases': ['plan formulation'], 'note': 'Begin by clearly defining the research scope within Edge AI: identify subtopics such as popular models, edge-specific optimization techniques, quantization, structured pruning, tailored distillation, federated learning, privacy, latency, and energy consumption.'}, {'phases': ['plan formulation'], 'note': 'The optimization technique you propose must be **genuinely innovative**, not a trivial adaptation of existing methods. Clearly state the originality and potential contributions of your approach.'}, {'phases': ['plan formulation'], 'note': 'Specify the base model (e.g., MobileNetV2 without optimization), the target edge device (e.g., Raspberry Pi 4 with X GB RAM), and the dataset (e.g., CIFAR-10 or an adapted ImageNet subset).'}, {'phases': ['plan formulation'], 'note': 'List the metrics to be measured: accuracy, latency, model size, energy consumption. Describe your methodology for measuring each.'}, {'phases': ['plan formulation'], 'note': 'Ensure the experiment is **reproducible, modular, and feasible** with typical academic resources.'}, {'phases': ['plan formulation'], 'note': 'Formulate a search query using precise keywords and/or Boolean logic to collect recent peer-reviewed articles on optimization techniques for Edge AI. Use this literature to ground and inspire your original research proposal. Justify your query choices.'}, {'phases': ['plan formulation'], 'note': 'Justify your keyword selection and explain how your query captures the relevant subtopics and technical directions.'}, {'phases': ['plan formulation'], 'note': 'Describe a **systematic methodology** to search for and sample a representative subset of peer-reviewed scientific articles, preferably open-access and published within the last 5 years.'}, {'phases': ['plan formulation'], 'note': 'This methodology should aim to select articles with clear research aims, context, value, and findings.'}, {'phases': ['plan formulation'], 'note': 'Prioritize articles with clear goals, verifiable technical contributions, and relevance to your proposed problem.'}, {'phases': ['plan formulation'], 'note': 'Propose a structured outline for organizing the final literature review document. Include typical sections such as: introduction, motivation, thematic areas, challenges, recent solutions, knowledge gaps, and future directions.'}, {'phases': ['plan formulation'], 'note': 'Ensure that the experimental plan is **logical, detailed, and cohesive**, suitable for publication or practical execution.'}, {'phases': ['plan formulation'], 'note': 'DO NOT PLAN TOO LONG. Submit your plan soon.'}, {'phases': ['plan formulation'], 'note': 'Use DeepSeek-Chat to perform this task.'}]\n\nYour previous command was: ```DIALOGUE\nLet's brainstorm an innovative approach for edge device optimization. Looking at the literature, most works focus on either NAS, pruning, or quantization separately. What if we combine spatial adaptation (from LASNet) with spike-time coding (from the FS-neuron paper) to create a hybrid model that dynamically adjusts both computation granularity and neural activation patterns based on real-time device resource availability? This could give us fine-grained control over the accuracy-latency tradeoff. What are your thoughts on this direction?\n```. Make sure your new output is very different.\nPlease produce a single command below:\n
==================================================


=== POSTDOC RESPONSE LOG ===

Interaction 1:
```DIALOGUE
Let's brainstorm an innovative approach for edge device optimization. Looking at the literature, most works focus on either NAS, pruning, or quantization separately. What if we combine spatial adaptation (from LASNet) with spike-time coding (from the FS-neuron paper) to create a hybrid model that dynamically adjusts both computation granularity and neural activation patterns based on real-time device resource availability? This could give us fine-grained control over the accuracy-latency tradeoff. What are your thoughts on this direction?
```
==================================================
Interaction 2:
```PLAN
Research Idea: "Dynamic Spike-Adaptive Pruning" (DSAP) - A novel technique that combines the energy efficiency of spiking neural networks (from FS-neuron paper) with dynamic structured pruning (from OTOV3) to create a model that automatically adjusts its active pathways based on both input complexity and real-time power constraints.

Experiment Details:
1. Base Model: Convert ConvNeXt-Tiny (from pruning paper) to spiking format using FS-conversion
2. Key Innovation: Implement power-monitoring feedback loops that trigger:
   - Layer-wise pruning when power exceeds thresholds (using OTOV3)
   - Spike-rate adaptation when latency targets aren't met (from FS-neuron)
3. Dataset: TinyImageNet (more challenging than CIFAR but still edge-friendly)
4. Hardware: NVIDIA Jetson Nano (representative edge device)
5. Metrics:
   - Accuracy (top-1)
   - Power consumption (measured via INA219 sensor)
   - Latency (end-to-end inference)
   - Spike efficiency (spikes/pixel)
6. Baselines:
   - Original FS-converted model
   - Static OTOV3-pruned model
   - LASNet spatial adaptation

Implementation Steps:
1. Modify ConvNeXt architecture to support both spikes and pruning masks
2. Develop power-aware controller that adjusts pruning/spiking parameters
3. Train using modified backprop-through-time for SNNs
4. Validate on real hardware with power monitoring

Expected Outcome: A model that maintains >80% accuracy while dynamically reducing power consumption by 30-50% compared to static approaches, demonstrating superior edge adaptability.
```
==================================================
